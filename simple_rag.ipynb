{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05461ae7-6298-47af-bdf3-68ce3345fafa",
   "metadata": {},
   "source": [
    "### Simple RAG using Oracle Vector Store\n",
    "* basata su Cohere command-r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8713f44e-9163-4d25-8bc6-64d431f32c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint\n",
    "\n",
    "import oracledb\n",
    "\n",
    "from langchain_community.vectorstores.oraclevs import OracleVS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import OCIGenAI\n",
    "\n",
    "# to compute embeddings vectors\n",
    "from langchain_community.embeddings import OCIGenAIEmbeddings\n",
    "\n",
    "from utils import load_configuration\n",
    "\n",
    "# private information\n",
    "from config_private import COMPARTMENT_ID, DB_USER, DB_PWD, DB_HOST_IP, DB_SERVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc2f6b-179e-48da-8533-0bb7fadb0580",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cacc926-517c-44f8-8587-1b1b67b90d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The general configuration is:\n",
      "\n",
      "{'embeddings': {'cohere': {},\n",
      "                'embed_model_type': 'OCI',\n",
      "                'oci': {'embed_batch_size': 90,\n",
      "                        'embed_endpoint': 'https://inference.generativeai.us-chicago-1.oci.oraclecloud.com',\n",
      "                        'embed_model': 'cohere.embed-multilingual-v3.0'}},\n",
      " 'llm': {'cohere': {'llm_model': 'command-r'},\n",
      "         'max_tokens': 1024,\n",
      "         'model_type': 'OCI',\n",
      "         'oci': {'endpoint': 'https://inference.generativeai.us-chicago-1.oci.oraclecloud.com',\n",
      "                 'llm_model': 'meta.llama-2-70b-chat'},\n",
      "         'temperature': 0.1},\n",
      " 'reranker': {'add_reranker': True,\n",
      "              'cohere_reranker_model': 'rerank-multilingual-v3.0'},\n",
      " 'retriever': {'top_k': 8, 'top_n': 4},\n",
      " 'text_splitting': {'books_dir': './books',\n",
      "                    'chunk_overlap': 50,\n",
      "                    'chunk_size': 1500},\n",
      " 'tracing': {'enable': False, 'langchain_project': 'workshop-1'},\n",
      " 'ui': {'add_references': True,\n",
      "        'do_streaming': True,\n",
      "        'hello_msg': 'Ciao, come posso aiutarti?',\n",
      "        'title': 'AI Assistant with LangChain ðŸ¦œ',\n",
      "        'verbose': False},\n",
      " 'vector_store': {'23ai': {'embeddings_bit': 32},\n",
      "                  'collection_name': 'ORACLE_KNOWLEDGE',\n",
      "                  'opensearch': {'bulk_size': 5000,\n",
      "                                 'engine': 'faiss',\n",
      "                                 'index_name': 'test1',\n",
      "                                 'opensearch_url': 'https://localhost:9200',\n",
      "                                 'ssl_assert_hostname': False,\n",
      "                                 'ssl_show_warn': False,\n",
      "                                 'use_ssl': True,\n",
      "                                 'verify_certs': False},\n",
      "                  'store_type': '23AI'}}\n"
     ]
    }
   ],
   "source": [
    "# Configure logging\n",
    "logger = logging.getLogger(\"ConsoleLogger\")\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# load the config in a toml file\n",
    "config = load_configuration()\n",
    "\n",
    "# embeddings model: we're using OCI GenAI multilingual Cohere\n",
    "OCI_EMBED_MODEL = config[\"embeddings\"][\"oci\"][\"embed_model\"]\n",
    "EMBED_ENDPOINT = config[\"embeddings\"][\"oci\"][\"embed_endpoint\"]\n",
    "\n",
    "LLM_ENDPOINT = config[\"llm\"][\"oci\"][\"endpoint\"]\n",
    "\n",
    "# number of docs retrieved for each query\n",
    "# reduced from config to simplify outpute here\n",
    "TOP_K = 4\n",
    "\n",
    "# to connect to DB\n",
    "# if you don't change, the port is 1521\n",
    "DSN = f\"{DB_HOST_IP}:1521/{DB_SERVICE}\"\n",
    "\n",
    "print(\"The general configuration is:\")\n",
    "print()\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0219ff4d-464b-4163-85c3-47dbbe382235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    "def print_metadata(v_metadata):\n",
    "    \"\"\"\n",
    "    this is the format:\n",
    "    {'source': './books/oracle-ai-vector-search-users-guide.pdf', 'page': 0}\n",
    "    \"\"\"\n",
    "    print(f\"- Source: {v_metadata['source']}, page: {v_metadata['page']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c664ea36-da21-4f17-b705-ca05bb296528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 16:13:46,376 - INFO - Connection successful!\n"
     ]
    }
   ],
   "source": [
    "# create client for Embeddings and AI Vector Search\n",
    "\n",
    "# Embed model here is needed to embed the query!\n",
    "# for embeddings we're using the extension that handles batching\n",
    "embed_model = OCIGenAIEmbeddings(\n",
    "    auth_type=\"API_KEY\",\n",
    "    model_id=OCI_EMBED_MODEL,\n",
    "    service_endpoint=EMBED_ENDPOINT,\n",
    "    compartment_id=COMPARTMENT_ID,\n",
    ")\n",
    "\n",
    "try:\n",
    "    # we need to provide a connection as input to OracleVS\n",
    "    connection = oracledb.connect(user=DB_USER, password=DB_PWD, dsn=DSN)\n",
    "    logger.info(\"Connection successful!\")\n",
    "\n",
    "    # get an instance of OracleVS\n",
    "    v_store = OracleVS(\n",
    "        client=connection,\n",
    "        table_name=\"ORACLE_KNOWLEDGE\",\n",
    "        distance_strategy=DistanceStrategy.COSINE,\n",
    "        embedding_function=embed_model,\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(\"Connection failed!\")\n",
    "    logger.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba61492-d3ed-480c-8b87-b7593ba99789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 16:13:47,595 - INFO - Retriever created...\n"
     ]
    }
   ],
   "source": [
    "# create a retriever from the Vector Store\n",
    "retriever = v_store.as_retriever(search_kwargs={\"k\": TOP_K})\n",
    "\n",
    "logger.info(\"Retriever created...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93b7068e-e984-49e9-8c2b-c79131c713e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Document retrieved from the knowledge base ---\n",
      "\n",
      "-------------------------------------------\n",
      "Document n. 1\n",
      "\n",
      "- Content:\n",
      "OracleÂ® Database\n",
      "Oracle AI Vector Search User's Guide\n",
      "23ai\n",
      "F87786-01\n",
      "May 2024\n",
      "\n",
      "- Source: ./books/oracle-ai-vector-search-users-guide.pdf, page: 0\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Document n. 2\n",
      "\n",
      "- Content:\n",
      "Manage the Different Categories of Vector Indexes\n",
      "5-8\n",
      "\n",
      "- Source: ./books/oracle-ai-vector-search-users-guide.pdf, page: 148\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Document n. 3\n",
      "\n",
      "- Content:\n",
      "1\n",
      "Overview\n",
      "Oracle AI Vector Search stores and indexes vector embeddings for fast retrieval and\n",
      "similarity search.\n",
      "â€¢Overview of Oracle AI Vector Search\n",
      "Oracle AI Vector Search is designed for Artificial Intelligence (AI) workloads and allows\n",
      "you to query data based on semantics, rather than keywords.\n",
      "â€¢Why Use Oracle AI Vector Search?\n",
      "One of the biggest benefits of Oracle AI Vector Search is that semantic search on\n",
      "unstructured data can be combined with relational search on business data in one single\n",
      "system.\n",
      "â€¢Oracle AI Vector Search Workflow\n",
      "A typical Oracle AI Vector Search workflow follows the included primary steps.\n",
      "Overview of Oracle AI Vector Search\n",
      "Oracle AI Vector Search is designed for Artificial Intelligence (AI) workloads and allows you to\n",
      "query data based on semantics, rather than keywords.\n",
      "VECTOR Data Type\n",
      "The VECTOR  data type is introduced with the release of Oracle Database 23ai, providing the\n",
      "foundation to store vector embeddings alongside business data in the database. Using\n",
      "embedding models, you can transform unstructured data into vector embeddings that can\n",
      "then be used for semantic queries on business data.\n",
      "See the following basic example of using the VECTOR  data type in a table definition:\n",
      "CREATE TABLE docs (INT doc_id, CLOB doc_text, VECTOR  doc_vector);\n",
      "For more information about the VECTOR  data type and how to use vectors in tables, see \n",
      "Create Tables Using the VECTOR Data Type.\n",
      "Vector Embeddings\n",
      "\n",
      "- Source: ./books/oracle-ai-vector-search-users-guide.pdf, page: 8\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Document n. 4\n",
      "\n",
      "- Content:\n",
      "Why Use Oracle AI Vector Search?\n",
      "                         The biggest benefit of Oracle AI Vector Search is \n",
      "that semantic search on unstructured data can be\n",
      "                         combined with relational search on business data in \n",
      "one single system.\n",
      "Example 3-13    BY chars MAX 200 OVERLAP 0 SPLIT BY none NORMALIZE none\n",
      "This example is the same as Example 3-1 , to contrast with Example 3-13  with normalization.\n",
      "Syntax:\n",
      "SELECT C.*\n",
      "FROM documentation_tab D, VECTOR_CHUNKS(D.text BY chars MAX 200 OVERLAP 0\n",
      "                           SPLIT BY none LANGUAGE american NORMALIZE none) C;\n",
      "Output:\n",
      "CHUNK_OFFSET CHUNK_LENGTH CHUNK_TEXT\n",
      "-----------------------------------------------------------------------------\n",
      "---------------------\n",
      "1         200          Oracle AI Vector Search stores and indexes vector \n",
      "embeddings for fast retrieval and similarity search.\n",
      "                          About Oracle AI Vector Search\n",
      "                          Vector Indexes are a new classification of \n",
      "specialized ind\n",
      "201         200           exes that are designed for Artificial Intelligence \n",
      "(AI) workloads that allow you to query data based\n",
      "                          on semantics, rather than keywords.\n",
      "                          Why Use Oracle AI Vector Search?\n",
      "                          The biggest benefit of O\n",
      "401         146           racle AI Vector Search is that semantic search on \n",
      "unstructured data can be combined with relational\n",
      "\n",
      "- Source: ./books/oracle-ai-vector-search-users-guide.pdf, page: 114\n",
      "-------------------------------------------\n",
      "\n",
      "CPU times: user 60.7 ms, sys: 40 ms, total: 101 ms\n",
      "Wall time: 589 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first let's test the semantic search\n",
    "question = \"What is AI Vector Search??\"\n",
    "\n",
    "result_docs = retriever.invoke(question)\n",
    "\n",
    "# display results\n",
    "\n",
    "print(\"\")\n",
    "print(\"--- Document retrieved from the knowledge base ---\")\n",
    "print()\n",
    "\n",
    "for i, doc in enumerate(result_docs):\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(f\"Document n. {i+1}\")\n",
    "    print(\"\")\n",
    "    print(\"- Content:\")\n",
    "    print(doc.page_content)\n",
    "    print(\"\")\n",
    "    print_metadata(doc.metadata)\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a9d691-62e7-47c0-ad9b-ed7ae3e29628",
   "metadata": {},
   "source": [
    "#### The entire RA chain in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "045322ea-66b8-4a35-8d37-fec4b50361df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt_template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\"\"\"\n",
    "rag_prompt = PromptTemplate.from_template(rag_prompt_template)\n",
    "\n",
    "# these one must be accessed in Chicago\n",
    "MODEL_ID_COHERE = \"cohere.command\"\n",
    "MODEL_ID_LLAMA = \"meta.llama-2-70b-chat\"\n",
    "\n",
    "llm = OCIGenAI(\n",
    "    model_id=MODEL_ID_COHERE,\n",
    "    service_endpoint=LLM_ENDPOINT,\n",
    "    compartment_id=COMPARTMENT_ID,\n",
    "    model_kwargs={\"temperature\": 0.1, \"max_tokens\": 1024},\n",
    ")\n",
    "\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": rag_prompt,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08d67ddb-0887-4b20-b23c-3c1ef162d38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Oracle AI Vector Search is a tool designed for AI workloads that allows users to perform semantic searches (searches based on the meaning of words rather than the words themselves) on unstructured data combined with relational searches on business data. All of this is stored and indexed in vector embeddings for fast retrieval and similarity search. \n",
      "\n",
      "The Vector data type was introduced in Oracle Database 23ai, which provides the tools necessary to store vector embeddings - unstructured data transformed into vector form for more accurate querying and searches. \n",
      "\n",
      "Some use cases for Oracle AI Vector Search include:\n",
      "\n",
      "- Combining relational and unstructured data searches\n",
      "- Pinpointing the most similar documents to a particular document or set of documents\n",
      "\n",
      "Would you like more details on any of these points? \n"
     ]
    }
   ],
   "source": [
    "response = rag.invoke(question)\n",
    "\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc46ad-1404-4490-aa6f-f28c813dea91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
