# parameters for user interface
[ui]
add_references = true
do_streaming = true
hello_msg = "Ciao, come posso aiutarti?"
title = "AI Assistant with LangChain ðŸ¦œ"
verbose = false

# enable tracing with langsmith
[tracing]
enable = true
langchain_project = "workshop-1"

[text_splitting]
books_dir = "./books"
chunk_overlap = 50
chunk_size = 1500

[embeddings]
embed_model_type = "OCI"

[embeddings.oci]
embed_batch_size = 90
embed_endpoint = "https://inference.generativeai.us-chicago-1.oci.oraclecloud.com"
embed_model = "cohere.embed-multilingual-v3.0"

[embeddings.cohere]

# vector store
# store_type: OPENSEARCH, 23AI
[vector_store]
collection_name = "ORACLE_KNOWLEDGE"
store_type = "OPENSEARCH"

[vector_store.opensearch]
bulk_size = 5000
engine = "faiss"
index_name = "test1"
opensearch_url = "https://localhost:9200"
ssl_assert_hostname = false
ssl_show_warn = false
use_ssl = true
verify_certs = false

[vector_store.o23ai]
embeddings_bit = 32

[reranker]
add_reranker = true
cohere_reranker_model = "rerank-multilingual-v3.0"

[retriever]
top_k = 8
top_n = 4

# general llm
[llm]
max_tokens = 1024
model_type = "COHERE"
temperature = 0.1

[llm.oci]
endpoint = "https://inference.generativeai.us-chicago-1.oci.oraclecloud.com"
llm_model = "meta.llama-2-70b-chat"

# can be connad-r-plus
[llm.cohere]
llm_model = "command-r"
